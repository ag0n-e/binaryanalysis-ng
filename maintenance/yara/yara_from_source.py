#!/usr/bin/env python3

# Binary Analysis Next Generation (BANG!)
#
# Copyright 2021-2022 - Armijn Hemel
# Licensed under the terms of the GNU Affero General Public License version 3
# SPDX-License-Identifier: AGPL-3.0-only

'''
This script processes source code archives and generates YARA rules
'''

import datetime
import hashlib
import json
import multiprocessing
import pathlib
import pickle
import re
import shutil
import subprocess
import sys
import tarfile
import tempfile
import uuid
import zipfile

import packageurl
import click

# import YAML module for the configuration
from yaml import load
from yaml import YAMLError
try:
    from yaml import CLoader as Loader
except ImportError:
    from yaml import Loader

from yara_config import YaraConfig, YaraConfigException

# lists of extenions for several programming language families
C_SRC_EXTENSIONS = ['.c', '.cc', '.cpp', '.cxx', '.c++', '.h', '.hh', '.hpp',
                    '.hxx', '.h++', '.l', '.y', '.qml', '.s', '.txx', '.dts',
                    '.dtsi', ]

JAVA_SRC_EXTENSIONS = ['.java', '.jsp', '.groovy', '.scala', '.kt']
JAVASCRIPT_SRC_EXTENSIONS = ['.js', '.dart']

SRC_EXTENSIONS = C_SRC_EXTENSIONS + JAVA_SRC_EXTENSIONS

TAR_SUFFIX = ['.tbz2', '.tgz', '.txz', '.tlz', '.tz', '.gz', '.bz2', '.xz', '.lzma']

# YARA escape sequences
ESCAPE = str.maketrans({'"': '\\"',
                        '\\': '\\\\',
                        '\t': '\\t',
                        '\n': '\\n'})

NAME_ESCAPE = str.maketrans({'.': '_',
                             '-': '_'})


def generate_yara(yara_directory, metadata, functions, variables, strings, tags, heuristics, fullword):
    generate_date = datetime.datetime.utcnow().isoformat()
    rule_uuid = uuid.uuid4()
    meta = '''
    meta:
        description = "Rule for %s"
        author = "Generated by BANG"
        date = "%s"
        uuid = "%s"
''' % (metadata['name'], generate_date, rule_uuid)

    for m in sorted(metadata):
        meta += '        %s = "%s"\n' % (m, metadata[m])

    #yara_file = yara_directory / ("%s-%s.yara" % (metadata['name'], metadata['name']))
    # TODO: origin and package?
    yara_file = yara_directory / ("%s-%s.yara" % (metadata['name'], metadata['language']))
    if tags == []:
        rule_name = 'rule rule_%s\n' % str(rule_uuid).translate(NAME_ESCAPE)
    else:
        rule_name = 'rule rule_%s: %s\n' % (str(rule_uuid).translate(NAME_ESCAPE), " ".join(tags))

    with yara_file.open(mode='w') as p:
        p.write(rule_name)
        p.write('{')
        p.write(meta)
        p.write('\n    strings:\n')

        if strings != set():
            # write the strings
            p.write("\n        // Extracted strings\n\n")
            counter = 1
            for s in strings:
                try:
                    if fullword:
                        p.write("        $string%d = \"%s\" fullword\n" % (counter, s))
                    else:
                        p.write("        $string%d = \"%s\"\n" % (counter, s))
                    counter += 1
                except:
                    pass

        if functions != set():
            # write the functions
            p.write("\n        // Extracted functions\n\n")
            counter = 1
            for s in functions:
                if fullword:
                    p.write("        $function%d = \"%s\" fullword\n" % (counter, s))
                else:
                    p.write("        $function%d = \"%s\"\n" % (counter, s))
                counter += 1

        if variables != set():
            # write the variable names
            p.write("\n        // Extracted variables\n\n")
            counter = 1
            for s in variables:
                if fullword:
                    p.write("        $variable%d = \"%s\" fullword\n" % (counter, s))
                else:
                    p.write("        $variable%d = \"%s\"\n" % (counter, s))
                counter += 1

        # TODO: find good heuristics of how many identifiers should be matched
        p.write('\n    condition:\n')
        if strings != set():
            p.write('        all of ($string*)')
            if not (functions == set() and variables == set()):
                p.write(' and\n')
            else:
                p.write('\n')
        if functions != set():
            p.write('        all of ($function*)')
            if variables != set():
                p.write(' and\n')
            else:
                p.write('\n')
        if variables != set():
            p.write('        all of ($variable*)\n')
        p.write('\n}')

    return yara_file.name


def extract_identifiers(yara_queue, temporary_directory, source_directory, yara_output_directory, yara_env, package):
    '''Unpack a tar archive based on extension and extract identifiers'''

    heuristics = {}
    while True:
        archive = yara_queue.get()

        package_archive = source_directory / archive
        try:
            tarchive = tarfile.open(name=package_archive)
            members = tarchive.getmembers()
        except Exception as e:
            yara_queue.task_done()
            continue

        identifiers_per_language = {}

        identifiers_per_language['c'] = {}
        identifiers_per_language['c']['strings'] = set()
        identifiers_per_language['c']['functions'] = set()
        identifiers_per_language['c']['variables'] = set()

        identifiers_per_language['java'] = {}
        identifiers_per_language['java']['strings'] = set()
        identifiers_per_language['java']['functions'] = set()
        identifiers_per_language['java']['variables'] = set()

        extracted = 0

        for m in members:
            extract_file = pathlib.Path(m.name)
            if extract_file.suffix.lower() in SRC_EXTENSIONS:
                extracted += 1
                break

        if extracted == 0:
            yara_queue.task_done()
            continue

        with open(package_archive, 'rb') as package_data:
            archive_hash = hashlib.new('sha256')
            archive_hash.update(package_data.read())
            package_hash = archive_hash.hexdigest()

        unpack_dir = tempfile.TemporaryDirectory(dir=temporary_directory)
        tarchive.extractall(path=unpack_dir.name)
        for m in members:
            extract_file = pathlib.Path(m.name)
            if extract_file.suffix.lower() in SRC_EXTENSIONS:
                if extract_file.suffix.lower() in C_SRC_EXTENSIONS:
                    language = 'c'
                elif extract_file.suffix.lower() in JAVA_SRC_EXTENSIONS:
                    language = 'java'

                # some path sanity checks (TODO: add more checks)
                if extract_file.is_absolute():
                    pass
                else:
                    member = open(unpack_dir.name / extract_file, 'rb')
                    member_data = member.read()
                    member.close()
                    member_hash = hashlib.new('sha256')
                    member_hash.update(member_data)
                    file_hash = member_hash.hexdigest()

                    # TODO: lookup hash in some database to detect third
                    # party/external components so they can be ignored

                    # first run xgettext
                    p = subprocess.Popen(['xgettext', '-a', '-o', '-', '--no-wrap', '--omit-header', '-'],
                                         stdin=subprocess.PIPE, stdout=subprocess.PIPE,
                                         stderr=subprocess.PIPE)
                    (stdout, stderr) = p.communicate(member_data)

                    if p.returncode == 0 and stdout != b'':
                        # process the output of standard out
                        lines = stdout.splitlines()
                        for line in lines:
                            if line.strip() == b'':
                                continue
                            if line.startswith(b'#'):
                                # skip comments, hints, etc.
                                continue
                            try:
                                decoded_line = line.decode()
                                if decoded_line.startswith('msgid '):
                                    msg_id = decoded_line[7:-1]
                                    if len(msg_id) >= yara_env['string_min_cutoff'] and len(msg_id) <= yara_env['string_max_cutoff']:
                                        # ignore whitespace-only strings
                                        if re.match(r'^\s+$', msg_id) is None:
                                            identifiers_per_language[language]['strings'].add(msg_id)
                            except:
                                pass

                    # then run ctags. Unfortunately ctags cannot process
                    # information from stdin so the file has to be extracted first
                    p = subprocess.Popen(['ctags', '--output-format=json', '-f', '-', unpack_dir.name / extract_file ],
                                         stdin=subprocess.PIPE, stdout=subprocess.PIPE,
                                         stderr=subprocess.PIPE)
                    (stdout, stderr) = p.communicate()
                    if p.returncode == 0 and stdout != b'':
                        lines = stdout.splitlines()
                        for line in lines:
                            try:
                                ctags_json = json.loads(line)
                            except Exception as e:
                                continue
                            try:
                                ctags_name = ctags_json['name']
                                if len(ctags_name) < yara_env['identifier_cutoff']:
                                    continue
                                if ctags_json['kind'] == 'field':
                                    identifiers_per_language[language]['variables'].add(ctags_name)
                                elif ctags_json['kind'] == 'variable':
                                    # Kotlin uses variables, not fields
                                    identifiers_per_language[language]['variables'].add(ctags_name)
                                elif ctags_json['kind'] == 'method':
                                    identifiers_per_language[language]['functions'].add(ctags_name)
                                elif ctags_json['kind'] == 'function':
                                    identifiers_per_language[language]['functions'].add(ctags_name)
                            except:
                                pass

        for language in identifiers_per_language:
            # TODO: name is actually not correct, as it assumes
            # there is only one binary with that particular name
            # inside a package.
            metadata= {}
            metadata['name'] = archive.name
            metadata['sha256'] = package_hash
            metadata['package'] = package
            metadata['language'] = language

            strings = sorted(identifiers_per_language[language]['strings'])
            variables = sorted(identifiers_per_language[language]['variables'])
            functions = sorted(identifiers_per_language[language]['functions'])

            if not (strings == [] and variables == [] and functions == []):
                yara_tags = yara_env['tags'] + [language]
                yara_name = generate_yara(yara_output_directory, metadata, functions, variables, strings, yara_tags, heuristics, yara_env['fullword'])

        unpack_dir.cleanup()
        yara_queue.task_done()


@click.command(short_help='process BANG result files and output YARA')
@click.option('--config-file', '-c', required=True, help='configuration file', type=click.File('r'))
@click.option('--source-directory', '-s', required=True, help='source code archive directory', type=click.Path(exists=True))
@click.option('--identifiers', '-i', help='pickle with low quality identifiers', type=click.File('rb'))
@click.option('--meta', '-m', required=True, help='file with meta information about a package', type=click.File('r'))
def main(config_file, source_directory, identifiers, meta):
    # test if ctags is available. This should be "universal ctags"
    # not "exuberant ctags"
    if shutil.which('ctags') is None:
        print("ctags program not found, exiting",
              file=sys.stderr)
        sys.exit(1)

    # test if xgettext is available
    if shutil.which('xgettext') is None:
        print("xgettext program not found, exiting",
              file=sys.stderr)
        sys.exit(1)

    source_directory = pathlib.Path(source_directory)

    # should be a real directory
    if not source_directory.is_dir():
        print("%s is not a directory, exiting." % source_directory, file=sys.stderr)
        sys.exit(1)

    # parse the package meta information
    try:
        package_meta_information = load(meta, Loader=Loader)
    except (YAMLError, PermissionError) as e:
        raise YaraConfigException(e.args)

    packages = []

    package = package_meta_information['package']

    # some sanity checks
    for release in package_meta_information['releases']:
        for release_version in release:
            release_filename = release[release_version]
            if not (source_directory / release_filename).exists():
                continue
            packages.append((release_filename, release[release_version]))

    # parse the configuration
    yara_config = YaraConfig(config_file)
    yara_env = yara_config.parse()

    lq_identifiers = {'elf': {'functions': [], 'variables': []},
                      'dex': {'functions': [], 'variables': []}}

    # read the pickle with identifiers
    if identifiers is not None:
        try:
            lq_identifiers = pickle.load(identifiers)
        except:
            pass

    yara_output_directory = yara_env['yara_directory'] / 'binary'

    yara_output_directory.mkdir(exist_ok=True)

    tags = ['source']

    # expand yara_env with source scanning specific values
    yara_env['tags'] = tags
    yara_env['lq_identifiers'] = lq_identifiers

    processmanager = multiprocessing.Manager()

    # create a queue for scanning files
    yara_queue = processmanager.JoinableQueue(maxsize=0)
    processes = []

    # walk the archives directory
    for archive in packages:
        tar_archive = source_directory / archive[1]
        if not tarfile.is_tarfile(tar_archive):
            continue
        yara_queue.put(pathlib.Path(archive[1]))

    # create processes for unpacking archives
    for i in range(0, yara_env['threads']):
        process = multiprocessing.Process(target=extract_identifiers,
                                          args=(yara_queue, yara_env['temporary_directory'],
                                                source_directory, yara_output_directory,
                                                yara_env, package))
        processes.append(process)

    # start all the processes
    for process in processes:
        process.start()

    yara_queue.join()

    # Done processing, terminate processes
    for process in processes:
        process.terminate()


if __name__ == "__main__":
    main()
